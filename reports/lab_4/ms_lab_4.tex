% !TEX options=--shell-escape
\documentclass[12pt]{article}
\input{packages.tex}
\input{borders.tex}
\renewcommand{\baselinestretch}{1.4} 

\begin{document}
\input{title_page.tex}
\input{commands.tex}


\tableofcontents
\addtocontents{toc}{~\hfill\par}
\vfill ~
\setcounter{section}{0}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage 
\section*{Постановка задачи}
\addcontentsline{toc}{section}{Постановка задачи}
\indent{\indent В данной лабораторной работе рассматриваются эмпирические функции распределения и ядерные оценки плотностей как статистические способы установления характера распределения. Требуется построить их для распределений из работы №1 на выборках размером $N = 20,\;60,\;100$ на отрезке $[-4,\;4]$, а также сделать выводы о данных оценках законов распределений. Формулы распределений представлены ниже}

\begin{equation}
	\label{dist:1}
	N(x, 0, 1) = \frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}} \;\text{-- стандартное нормальное}
\end{equation}
 
\begin{equation}
	C(x, 0, 1) = \frac{1}{\pi(1 + x^2)} \;\text{-- Коши} \label{dist:2}
\end{equation}

\begin{equation}
	L(x, 0, \frac{1}{\sqrt{2}}) = \frac{1}{\sqrt{2}}e^{{-\sqrt{2}|x|}} \;\text{-- Лаплас} \label{dist:3}
\end{equation}

\begin{equation} 
	U(x, -\sqrt{3}, \sqrt{3}) = 
    \begin{cases}
        \frac{1}{2\sqrt{3}}, \: |x| \leq \sqrt{3}\\
        \;\; 0, \:\:\:|x| > \sqrt{3}
    \end{cases}
    \;\text{-- равномерное} \label{dist:4}
\end{equation}

\begin{equation}
    P(\lambda) = \frac{e^{-\lambda}}{k!}\lambda^k , \; \lambda = 2\;\text{-- Пуассон} \label{dist:5}
\end{equation}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Описание метода}
\addcontentsline{toc}{section}{Описание метода}
\indent{\indent Пусть имеется некоторая выборка объемом $n: \; x_1, \ldots, \; x_n; \; x_i \in \mathbb{R}$. Эмпирической функцией распределения называют}

\begin{equation} 
    \hat{F_n}(x) = \frac{1}{n} \sum_{i=1}^{n}{u(x - x_i)}, \; \label{eq:1} \text{где}
\end{equation}

\begin{equation} 
    u(z) = 
    \begin{cases}
        1, \; z \geq 0 \\
        0, \; z \leq 0
    \end{cases}
    \text{ – фунция Хевисайда} 
    \label{eq:2}
\end{equation}

Ядерная оценка плотности определяется формулой

\begin{equation}
    \hat{f}_{n, h_n}(x)=\frac{1}{nh_n} \sum_{i=1}^{n}{K \left(\frac{x - x_i}{h_n}\right)}, \; \label{eq:3} \text{где $K(u)$ – ядро, $h = h_n$ – параметр сглаживания}
\end{equation}

Ядро $K(u)$  – это вещественнозначная функция со следующими свойствами

\begin{enumerate}
    \item $K(u) \geq 0$
    \item $K(-u) = K(u)$
    \item $\displaystyle \int_{-\infty}^{+\infty}{K(u)du} = 1$
\end{enumerate}
\indent{\indent Ядерная оценка плотности сглаживает каждый элемент выборки до плавного участка, форма которого определяется функцией ядра $K(u)$. Затем функция суммирует все участки, чтобы получить оценку плотности. В данной работе будем использовать ядро Гаусса, заданное формулой}

\begin{equation}
    K(u) = \frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}} \label{eq:4}
\end{equation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Реализация}
\addcontentsline{toc}{section}{Реализация}
\indent{\indentДля выполнения поставленной задачи будем пользоваться библиотеками для языка Python: \textit{numpy, scipy} -- расчеты, законы распределения вероятностей; \textit{matplotlib, seaborn} -- визуализация результатов. Ход работы:}
\begin{itemize}
    \item Задаем распределение с заданными параметрами 
    \item Генерируем случайные выборки из распределений объемами $n = 20, \; 60, \; 100$
    \item Для отсортированных выборок из распределений задаем вектор значений $y = [\frac{1}{n}, \frac{2}{n}, \ldots, 1]$ и строим ступенчатый график - эмпирическую функцию распределения 
    \item По формулам \eqref{eq:3}, \eqref{eq:4} вычисляем ядерные оценки плотностей для параметров сглаживания $h$ для всех выборок и строим графики 
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage
\section*{Результат}
\addcontentsline{toc}{section}{Результат}


\textbf{Эмпирические и теоретические функции распределения} 
\threeimage{em_norm_20}{em_norm_60}{em_norm_100}{нормального распределения}

\threeimage{em_uni_20}{em_uni_60}{em_uni_100}{равномерного распределения}

\threeimage{em_cauch_20}{em_cauch_60}{em_cauch_100}{распределения Коши}

\threeimage{em_lap_20}{em_lap_60}{em_lap_100}{распределения Лапласа}

\threeimage{em_pois_20}{em_pois_60}{em_pois_100}{распределения Пуассона}
\newpage
\textbf{Ядерные оценки плотностей и функции плотностей распределения} 

\triplethreeimage{ker_norm_20}{ker_norm_60}{ker_norm_100}{нормального распределения}
\triplethreeimage{ker_uni_20}{ker_uni_60}{ker_uni_100}{равномерного распределения}
\triplethreeimage{ker_cauch_20}{ker_cauch_60}{ker_cauch_100}{распределения Коши}
\triplethreeimage{ker_lap_20}{ker_lap_60}{ker_lap_100}{распределения Лапласа}
\triplethreeimage{ker_pois_20}{ker_pois_60}{ker_pois_100}{распределения Пуассона}

\indent{ Описывая полученные результаты, можно заключить, что чем больше выборка, тем точнее эмпирическая функция распределения оценивает теоретическую.}

\indent{ Точность ядерной оценки плотности сильно варьируется в зависимости от значения сглаживающего параметра $h$. Так, при $h \to 0$ оценка плотности точна на выборочных данных, но только на них, и такая функция не способна описать характер распределения. Выбрав $(n + 1)$-ое значение из распределения, мы столкнемся с тем, что, вероятнее всего, статистическая функция плохо оценит значение теоретической функции плотности вероятности для данного выборочного элемента. В таком случае можно говорить о плохой способности функции к обобщению.}

\indent{ Напротив, при увеличении параметра $h$ ядерная оценка плотности показывает себя плохо даже на выборочных данных и вообще не позволяет понять характера распределения.}

\indent{ Выбор параметра сглаживания следует производить исходя из того, насколько плотно распределение объектов выборки; большей плотности соответствует выбор меньшего параметра и наоборот.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage
\begin{thebibliography}{}
    \bibitem{ms_1}\textit{Conlen, M.} Kernel Density Estimation (2019). URL: https://mathisonian.github.io/kde/
\end{thebibliography}


\end{document}{}